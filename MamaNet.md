# MamaNet
## Author
* Wei Jiang, Suanfamama, wei@suanfamama.com
* Mama Xiao, Suanfamama, mama.xiao@suanfamama.com

## Implementation
* PyTorch Framework

## Dataset
* Fashion Images
* Fashion Videos
* Fashion Sounds
* Fashion Text

## Model Design
* Improved DiT

## Evaluation Framework
* Fr√©chet Inception Distance (FID): FID is a widely used metric to evaluate the quality of images generated by generative models. It measures the distance between the feature distributions of real and generated images using a pre-trained Inception network.
* (Optional) Gflops: Giga-floating-point operations per second, a measure of computational complexity.

## Key Factors for image generation quality
* model size
* patch size

## from Text to Image
* 

## from Image to Video & Multimodal

* Temporal Modeling: Introduce temporal layers that can capture the sequence of frames in a video. Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), or Gated Recurrent Units (GRUs) can be used to model the temporal dependencies.

* 3D Convolutional Networks: Utilize 3D convolutions that can process spatial-temporal features within the video. This allows the model to learn from both spatial and temporal information simultaneously.

* Two-Stream Networks: Implement a two-stream architecture where one stream processes spatial features from individual frames and the other stream processes temporal features. These streams can then be combined to make predictions that consider both spatial and temporal contexts.

* Attention Mechanisms: Apply attention mechanisms to focus on relevant parts of the video sequence, which can be especially useful for tasks like video captioning or question answering about a video.

* Data Augmentation: Generate synthetic video data or augment existing data to increase the robustness of the model, particularly for tasks where data scarcity is an issue.
